{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "EeqS7wgy6nkQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew\n",
        "from scipy.stats.stats import pearsonr\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "J_F6Oc7I62ar"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/KhaledElTahan/DeepLearning/master/Labs/lab1/lab1_housing_train.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/KhaledElTahan/DeepLearning/master/Labs/lab1/lab1_housing_test.csv\")"
      ],
      "metadata": {
        "id": "R-e5tWL_69q0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "igZbTjwd7DXq",
        "outputId": "b8306275-3f3a-4407-d4a8-6ece72280c2d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7a3743e9-e329-45a9-ac3b-d2b855fdf75f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a3743e9-e329-45a9-ac3b-d2b855fdf75f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a3743e9-e329-45a9-ac3b-d2b855fdf75f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a3743e9-e329-45a9-ac3b-d2b855fdf75f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all the data\n",
        "# We do this to be able to preprocess on the whole dataset\n",
        "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
        "                      test.loc[:,'MSSubClass':'SaleCondition']))\n",
        "\n",
        "# Log transform the target y in training data - by reference inside all\n",
        "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
        "\n",
        "# Log transform skewed numeric features:\n",
        "\n",
        "# Get Numerical Fields\n",
        "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index \n",
        "\n",
        "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewnessc\n",
        "skewed_feats = skewed_feats[skewed_feats > 0.75] # Get Skewed Columns\n",
        "skewed_feats = skewed_feats.index # Get Skewed Columns indices\n",
        "\n",
        "# Log scale skewed columns\n",
        "# Normalize the skewed distribution for better regression\n",
        "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
        "\n",
        "# Create Dummy variables for the categorical features \n",
        "all_data = pd.get_dummies(all_data) \n",
        "\n",
        "# Replace the numeric missing values (NaN's) with the mean of their respective columns\n",
        "all_data = all_data.fillna(all_data.mean())\n",
        "\n",
        "# Split the data to training & testing\n",
        "X_train = all_data[:train.shape[0]]\n",
        "X_test = all_data[train.shape[0]:]\n",
        "y = train.SalePrice\n",
        "\n",
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "# z = (x - u) / s\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "\n",
        "#split training data into training & validation, default splitting is 25% validation\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y, random_state = 3)"
      ],
      "metadata": {
        "id": "uNg3tgmn7YAA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Dense(1,input_shape=(X_tr.shape[1],),kernel_regularizer=regularizers.l2(0.1)))"
      ],
      "metadata": {
        "id": "zRVer3XY72zO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"mean_squared_error\", optimizer = \"Adam\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7tbIm-stCoF",
        "outputId": "7bc22a7e-cf9f-49e9-90a7-92551e23b1e2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289\n",
            "Trainable params: 289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2aq9MmZtIhA",
        "outputId": "7bd655a4-e491-46f4-fc8a-ed08964f9c1f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 1s 5ms/step - loss: 147.2062 - val_loss: 147.2394\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 145.3190 - val_loss: 148.1759\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 143.6806 - val_loss: 149.2300\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 142.1358 - val_loss: 150.2806\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 140.7442 - val_loss: 151.6037\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 139.3278 - val_loss: 152.8650\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 137.9389 - val_loss: 154.2615\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 136.5972 - val_loss: 155.8165\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 135.4464 - val_loss: 157.2916\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 134.0806 - val_loss: 159.0571\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 132.8560 - val_loss: 160.8337\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 131.6557 - val_loss: 162.5783\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 130.4767 - val_loss: 164.5816\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 129.3141 - val_loss: 166.5877\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 128.1549 - val_loss: 168.7205\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 127.0475 - val_loss: 170.8397\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 125.9575 - val_loss: 172.8364\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 124.8834 - val_loss: 175.1240\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 123.8214 - val_loss: 177.4003\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 122.7364 - val_loss: 179.7627\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 121.7362 - val_loss: 182.1038\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 120.6980 - val_loss: 184.4257\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 119.6816 - val_loss: 186.8252\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 118.7403 - val_loss: 189.2623\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 117.7575 - val_loss: 192.0106\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 116.7905 - val_loss: 194.4649\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 115.8652 - val_loss: 197.1806\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 114.9553 - val_loss: 199.8578\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 114.0250 - val_loss: 202.4289\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 113.0900 - val_loss: 205.1467\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 112.2134 - val_loss: 207.9891\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 111.3466 - val_loss: 210.5721\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 110.4418 - val_loss: 213.4266\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 109.5815 - val_loss: 216.3498\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 108.7528 - val_loss: 219.0607\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 107.9060 - val_loss: 221.9360\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 107.0465 - val_loss: 224.9614\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 106.2715 - val_loss: 227.5928\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 105.4558 - val_loss: 230.5121\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 104.6480 - val_loss: 233.4750\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 103.8848 - val_loss: 236.1641\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 103.1141 - val_loss: 238.7952\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 102.3149 - val_loss: 241.6850\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 101.5223 - val_loss: 244.7341\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 100.8019 - val_loss: 247.8490\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 100.0637 - val_loss: 250.8202\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 99.3048 - val_loss: 253.8279\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 98.5199 - val_loss: 256.4120\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 97.7853 - val_loss: 259.1777\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 97.0731 - val_loss: 262.1742\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 96.3721 - val_loss: 265.2950\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 95.6764 - val_loss: 268.0952\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 94.9571 - val_loss: 270.9694\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 94.2493 - val_loss: 274.0293\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 93.5936 - val_loss: 276.9170\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 92.8978 - val_loss: 279.8388\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 92.2082 - val_loss: 282.6434\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 91.5218 - val_loss: 285.3716\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 90.8567 - val_loss: 288.1805\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 90.2031 - val_loss: 290.8725\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 89.5664 - val_loss: 293.4428\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 88.9218 - val_loss: 296.3475\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 88.2553 - val_loss: 299.1826\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 87.6219 - val_loss: 301.9727\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 86.9772 - val_loss: 304.5048\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 86.3734 - val_loss: 307.1477\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 85.7508 - val_loss: 309.8795\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 85.1635 - val_loss: 312.5424\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 84.5518 - val_loss: 314.8225\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 83.9227 - val_loss: 317.6276\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 83.3184 - val_loss: 320.1074\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 82.7059 - val_loss: 322.3755\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 82.1414 - val_loss: 324.5341\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 81.5220 - val_loss: 326.8019\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 80.9559 - val_loss: 328.9783\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 80.3456 - val_loss: 331.1073\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 79.8124 - val_loss: 333.4688\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 79.2243 - val_loss: 335.2417\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 78.6559 - val_loss: 337.3145\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 78.0882 - val_loss: 339.4961\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 77.5642 - val_loss: 341.1082\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 76.9969 - val_loss: 342.7716\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 76.4587 - val_loss: 344.2162\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 75.8863 - val_loss: 345.8857\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 75.3287 - val_loss: 347.5981\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 74.7852 - val_loss: 349.1450\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 74.2793 - val_loss: 350.5279\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 73.7542 - val_loss: 352.0595\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 73.2145 - val_loss: 353.2171\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 72.6680 - val_loss: 354.8203\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 72.1543 - val_loss: 355.8961\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 71.6830 - val_loss: 357.0249\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 71.1492 - val_loss: 358.2501\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 70.6346 - val_loss: 359.2082\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 70.1189 - val_loss: 359.9521\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 69.6221 - val_loss: 360.9298\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 69.1307 - val_loss: 361.8456\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 68.6213 - val_loss: 362.4434\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 68.1349 - val_loss: 362.9399\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 67.5962 - val_loss: 363.2875\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 67.1040 - val_loss: 363.8328\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 66.6183 - val_loss: 364.3182\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 66.1264 - val_loss: 364.6309\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 65.6542 - val_loss: 364.8039\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 65.1965 - val_loss: 364.6846\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 64.6921 - val_loss: 364.8956\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 64.2222 - val_loss: 364.6491\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 63.7154 - val_loss: 364.4601\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 63.2569 - val_loss: 364.5797\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 62.8072 - val_loss: 364.5302\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 62.3205 - val_loss: 363.8968\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 61.8636 - val_loss: 363.4997\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 61.3936 - val_loss: 363.0973\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 60.9375 - val_loss: 362.5674\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 60.4685 - val_loss: 361.8278\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 60.0408 - val_loss: 361.3026\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 59.5838 - val_loss: 360.3557\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 59.1083 - val_loss: 359.5676\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 58.6641 - val_loss: 358.6772\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 58.2208 - val_loss: 357.8146\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 57.7909 - val_loss: 356.4312\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 57.3304 - val_loss: 355.3820\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 56.9058 - val_loss: 354.4808\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 56.4788 - val_loss: 353.4628\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 56.0142 - val_loss: 352.0466\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 55.5936 - val_loss: 350.8309\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 55.1775 - val_loss: 349.5869\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 54.7314 - val_loss: 348.2162\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 54.3196 - val_loss: 346.8356\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 53.8646 - val_loss: 345.0825\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 53.4389 - val_loss: 343.5706\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 53.0332 - val_loss: 341.7948\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 52.5876 - val_loss: 340.5205\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 52.1723 - val_loss: 338.7695\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 51.7621 - val_loss: 337.1969\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 51.3472 - val_loss: 335.5184\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 50.9231 - val_loss: 333.4432\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 50.5367 - val_loss: 331.7054\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 50.1190 - val_loss: 329.8653\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 49.7001 - val_loss: 327.9704\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 49.2990 - val_loss: 326.1643\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 48.8997 - val_loss: 324.0755\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 48.5218 - val_loss: 322.0211\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 48.0939 - val_loss: 320.1338\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 47.7011 - val_loss: 318.0132\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 47.3386 - val_loss: 315.9086\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 46.9173 - val_loss: 314.0039\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 46.5154 - val_loss: 311.7674\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 46.1366 - val_loss: 309.7942\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 45.7466 - val_loss: 307.7623\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 45.3741 - val_loss: 305.6613\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 44.9781 - val_loss: 303.5468\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 44.5894 - val_loss: 301.4361\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 44.1870 - val_loss: 299.3419\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 43.8409 - val_loss: 297.5773\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 43.4480 - val_loss: 295.2437\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 43.0626 - val_loss: 292.7249\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 42.7012 - val_loss: 290.7049\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 42.3452 - val_loss: 288.3664\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 41.9534 - val_loss: 285.9943\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 41.5603 - val_loss: 283.8666\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 41.2097 - val_loss: 281.5220\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 40.8601 - val_loss: 279.2248\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 40.4880 - val_loss: 276.8634\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 40.1134 - val_loss: 274.7913\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 39.7653 - val_loss: 272.5238\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 39.4122 - val_loss: 270.3020\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 39.0676 - val_loss: 267.9818\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 38.7127 - val_loss: 265.7657\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 38.3471 - val_loss: 263.4938\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 37.9937 - val_loss: 261.4569\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 37.6560 - val_loss: 259.3132\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 37.3119 - val_loss: 257.0592\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 36.9782 - val_loss: 254.8959\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 36.6453 - val_loss: 252.4855\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 36.3011 - val_loss: 250.4557\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 35.9459 - val_loss: 247.9122\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 35.6145 - val_loss: 245.6338\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 35.2875 - val_loss: 243.6282\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 34.9402 - val_loss: 241.3250\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 34.6039 - val_loss: 239.0677\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 34.2630 - val_loss: 236.8056\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 33.9491 - val_loss: 234.6807\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 33.6265 - val_loss: 232.5414\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 33.3167 - val_loss: 230.1432\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 32.9759 - val_loss: 228.0436\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 32.6456 - val_loss: 225.9211\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 32.3150 - val_loss: 223.9509\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 32.0024 - val_loss: 221.9612\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 31.6813 - val_loss: 219.8476\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 31.3845 - val_loss: 217.7568\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 31.0688 - val_loss: 215.5166\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 30.7523 - val_loss: 213.4022\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 30.4469 - val_loss: 211.1387\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 30.1262 - val_loss: 209.0609\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 29.8322 - val_loss: 207.0935\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 29.5247 - val_loss: 205.0291\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 29.2242 - val_loss: 202.8131\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 28.9412 - val_loss: 200.8533\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 28.6217 - val_loss: 198.5397\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 28.3196 - val_loss: 196.9702\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 28.0344 - val_loss: 194.8127\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 27.7409 - val_loss: 192.9165\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 27.4427 - val_loss: 190.9438\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 27.1413 - val_loss: 188.9674\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 26.8528 - val_loss: 186.9398\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 26.5688 - val_loss: 185.0736\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 26.2819 - val_loss: 183.0911\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 26.0132 - val_loss: 181.1086\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 25.7240 - val_loss: 179.1342\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 25.4424 - val_loss: 177.2662\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 25.1784 - val_loss: 175.3812\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 24.8969 - val_loss: 173.6064\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 24.6309 - val_loss: 171.8314\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 24.3399 - val_loss: 169.7740\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 24.0796 - val_loss: 168.1319\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 23.7885 - val_loss: 166.3300\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 23.5417 - val_loss: 164.6488\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 23.2632 - val_loss: 162.7386\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 23.0026 - val_loss: 160.8310\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 22.7391 - val_loss: 159.2816\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 22.4831 - val_loss: 157.6271\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 22.2210 - val_loss: 155.6228\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 21.9677 - val_loss: 154.0419\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 21.7079 - val_loss: 152.1800\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 21.4587 - val_loss: 150.5086\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 21.2103 - val_loss: 148.8354\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 20.9628 - val_loss: 146.9706\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 20.7246 - val_loss: 145.3236\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 20.4612 - val_loss: 143.7906\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 20.2435 - val_loss: 142.1073\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 19.9643 - val_loss: 140.2253\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 19.7475 - val_loss: 138.6126\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 19.4912 - val_loss: 136.9778\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 19.2545 - val_loss: 135.4724\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 19.0481 - val_loss: 133.8894\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 18.7781 - val_loss: 132.2634\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 18.5509 - val_loss: 130.8774\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 18.3360 - val_loss: 129.1079\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 18.1020 - val_loss: 127.5074\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 17.8872 - val_loss: 126.0754\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 17.6324 - val_loss: 124.6013\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 17.4225 - val_loss: 123.0328\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 17.2146 - val_loss: 121.5530\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 16.9674 - val_loss: 120.0896\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 16.7637 - val_loss: 118.6737\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 16.5326 - val_loss: 116.9624\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 16.3057 - val_loss: 115.4812\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 16.1099 - val_loss: 114.1886\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 15.8842 - val_loss: 112.6383\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 15.6711 - val_loss: 111.1623\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 15.4703 - val_loss: 109.6508\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 15.2629 - val_loss: 108.3047\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 15.0463 - val_loss: 107.0585\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 14.8472 - val_loss: 105.4996\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 14.6516 - val_loss: 104.4255\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 14.4534 - val_loss: 102.9438\n",
            "Epoch 258/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 14.2563 - val_loss: 101.5478\n",
            "Epoch 259/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 14.0470 - val_loss: 100.3323\n",
            "Epoch 260/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 13.8463 - val_loss: 98.7937\n",
            "Epoch 261/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 13.6648 - val_loss: 97.4201\n",
            "Epoch 262/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 13.4652 - val_loss: 96.1281\n",
            "Epoch 263/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 13.2791 - val_loss: 94.8550\n",
            "Epoch 264/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 13.0988 - val_loss: 93.5748\n",
            "Epoch 265/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 12.8974 - val_loss: 92.2675\n",
            "Epoch 266/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 12.7138 - val_loss: 91.0620\n",
            "Epoch 267/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 12.5209 - val_loss: 89.7881\n",
            "Epoch 268/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 12.3442 - val_loss: 88.7493\n",
            "Epoch 269/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 12.1567 - val_loss: 87.3606\n",
            "Epoch 270/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 11.9801 - val_loss: 85.9873\n",
            "Epoch 271/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.8007 - val_loss: 84.9677\n",
            "Epoch 272/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.6227 - val_loss: 83.7371\n",
            "Epoch 273/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 11.4462 - val_loss: 82.5218\n",
            "Epoch 274/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 11.2825 - val_loss: 81.2802\n",
            "Epoch 275/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 11.1000 - val_loss: 80.1429\n",
            "Epoch 276/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.9337 - val_loss: 78.8925\n",
            "Epoch 277/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.7784 - val_loss: 77.9347\n",
            "Epoch 278/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.5816 - val_loss: 76.7451\n",
            "Epoch 279/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.4327 - val_loss: 75.5924\n",
            "Epoch 280/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.2716 - val_loss: 74.3717\n",
            "Epoch 281/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.1078 - val_loss: 73.3650\n",
            "Epoch 282/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.9336 - val_loss: 72.1153\n",
            "Epoch 283/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 9.7811 - val_loss: 70.8585\n",
            "Epoch 284/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.6229 - val_loss: 69.8744\n",
            "Epoch 285/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.4719 - val_loss: 68.8171\n",
            "Epoch 286/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.3035 - val_loss: 67.8188\n",
            "Epoch 287/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.1649 - val_loss: 66.7639\n",
            "Epoch 288/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 9.0115 - val_loss: 65.7989\n",
            "Epoch 289/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 8.8585 - val_loss: 64.5790\n",
            "Epoch 290/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.7056 - val_loss: 63.5118\n",
            "Epoch 291/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.5617 - val_loss: 62.5637\n",
            "Epoch 292/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.4109 - val_loss: 61.5915\n",
            "Epoch 293/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.2708 - val_loss: 60.6513\n",
            "Epoch 294/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.1234 - val_loss: 59.5812\n",
            "Epoch 295/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.9867 - val_loss: 58.6840\n",
            "Epoch 296/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 7.8432 - val_loss: 57.6194\n",
            "Epoch 297/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 7.7087 - val_loss: 56.7422\n",
            "Epoch 298/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.5654 - val_loss: 55.6108\n",
            "Epoch 299/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 7.4332 - val_loss: 54.7995\n",
            "Epoch 300/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.2965 - val_loss: 53.9033\n",
            "Epoch 301/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.1666 - val_loss: 52.9152\n",
            "Epoch 302/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 7.0357 - val_loss: 51.9420\n",
            "Epoch 303/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.9109 - val_loss: 50.9550\n",
            "Epoch 304/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.7788 - val_loss: 50.1828\n",
            "Epoch 305/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.6582 - val_loss: 49.4229\n",
            "Epoch 306/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.5280 - val_loss: 48.6229\n",
            "Epoch 307/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.4057 - val_loss: 47.6378\n",
            "Epoch 308/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.2843 - val_loss: 46.8257\n",
            "Epoch 309/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.1561 - val_loss: 46.0624\n",
            "Epoch 310/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.0436 - val_loss: 45.1073\n",
            "Epoch 311/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.9195 - val_loss: 44.1976\n",
            "Epoch 312/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.8082 - val_loss: 43.4833\n",
            "Epoch 313/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.6907 - val_loss: 42.6312\n",
            "Epoch 314/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 5.5775 - val_loss: 41.8176\n",
            "Epoch 315/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.4678 - val_loss: 40.9290\n",
            "Epoch 316/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.3576 - val_loss: 40.2641\n",
            "Epoch 317/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 5.2479 - val_loss: 39.4508\n",
            "Epoch 318/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.1447 - val_loss: 38.5758\n",
            "Epoch 319/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.0354 - val_loss: 37.8787\n",
            "Epoch 320/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.9340 - val_loss: 37.1701\n",
            "Epoch 321/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.8272 - val_loss: 36.4119\n",
            "Epoch 322/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.7258 - val_loss: 35.6550\n",
            "Epoch 323/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.6211 - val_loss: 34.9845\n",
            "Epoch 324/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 4.5256 - val_loss: 34.2294\n",
            "Epoch 325/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.4266 - val_loss: 33.5206\n",
            "Epoch 326/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 4.3272 - val_loss: 32.9604\n",
            "Epoch 327/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.2402 - val_loss: 32.1275\n",
            "Epoch 328/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.1380 - val_loss: 31.4886\n",
            "Epoch 329/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.0414 - val_loss: 30.8969\n",
            "Epoch 330/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.9539 - val_loss: 30.1894\n",
            "Epoch 331/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.8588 - val_loss: 29.5035\n",
            "Epoch 332/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.7756 - val_loss: 28.8255\n",
            "Epoch 333/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.6888 - val_loss: 28.2535\n",
            "Epoch 334/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.6013 - val_loss: 27.5872\n",
            "Epoch 335/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.5211 - val_loss: 26.9259\n",
            "Epoch 336/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.4351 - val_loss: 26.1865\n",
            "Epoch 337/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.3479 - val_loss: 25.6943\n",
            "Epoch 338/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.2699 - val_loss: 25.1220\n",
            "Epoch 339/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.1933 - val_loss: 24.5476\n",
            "Epoch 340/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.1135 - val_loss: 23.9477\n",
            "Epoch 341/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.0337 - val_loss: 23.4691\n",
            "Epoch 342/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.9592 - val_loss: 22.8961\n",
            "Epoch 343/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.8879 - val_loss: 22.2845\n",
            "Epoch 344/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.8138 - val_loss: 21.7934\n",
            "Epoch 345/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.7468 - val_loss: 21.3352\n",
            "Epoch 346/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.6749 - val_loss: 20.8172\n",
            "Epoch 347/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.5940 - val_loss: 20.2736\n",
            "Epoch 348/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.5324 - val_loss: 19.8302\n",
            "Epoch 349/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.4614 - val_loss: 19.2398\n",
            "Epoch 350/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.3958 - val_loss: 18.7838\n",
            "Epoch 351/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.3338 - val_loss: 18.2606\n",
            "Epoch 352/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.2726 - val_loss: 17.9242\n",
            "Epoch 353/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.2042 - val_loss: 17.3320\n",
            "Epoch 354/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.1414 - val_loss: 16.9342\n",
            "Epoch 355/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.0818 - val_loss: 16.4522\n",
            "Epoch 356/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.0212 - val_loss: 15.9847\n",
            "Epoch 357/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.9667 - val_loss: 15.6241\n",
            "Epoch 358/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.9059 - val_loss: 15.1344\n",
            "Epoch 359/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.8523 - val_loss: 14.7560\n",
            "Epoch 360/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.8010 - val_loss: 14.3653\n",
            "Epoch 361/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.7445 - val_loss: 13.9488\n",
            "Epoch 362/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6910 - val_loss: 13.5307\n",
            "Epoch 363/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6397 - val_loss: 13.1479\n",
            "Epoch 364/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.5913 - val_loss: 12.8071\n",
            "Epoch 365/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5397 - val_loss: 12.4132\n",
            "Epoch 366/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4928 - val_loss: 12.0435\n",
            "Epoch 367/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4472 - val_loss: 11.6862\n",
            "Epoch 368/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.3984 - val_loss: 11.3353\n",
            "Epoch 369/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.3535 - val_loss: 10.9801\n",
            "Epoch 370/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.3110 - val_loss: 10.6552\n",
            "Epoch 371/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2676 - val_loss: 10.3077\n",
            "Epoch 372/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2237 - val_loss: 9.9742\n",
            "Epoch 373/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.1851 - val_loss: 9.7030\n",
            "Epoch 374/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1427 - val_loss: 9.3940\n",
            "Epoch 375/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1037 - val_loss: 9.0663\n",
            "Epoch 376/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.0653 - val_loss: 8.7516\n",
            "Epoch 377/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0265 - val_loss: 8.4702\n",
            "Epoch 378/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9918 - val_loss: 8.1979\n",
            "Epoch 379/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9561 - val_loss: 7.9267\n",
            "Epoch 380/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 7.6320\n",
            "Epoch 381/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8875 - val_loss: 7.3897\n",
            "Epoch 382/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8565 - val_loss: 7.0711\n",
            "Epoch 383/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8247 - val_loss: 6.8932\n",
            "Epoch 384/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7929 - val_loss: 6.6566\n",
            "Epoch 385/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7613 - val_loss: 6.3782\n",
            "Epoch 386/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 6.1339\n",
            "Epoch 387/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7053 - val_loss: 5.8971\n",
            "Epoch 388/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6771 - val_loss: 5.6941\n",
            "Epoch 389/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6507 - val_loss: 5.5035\n",
            "Epoch 390/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 5.2916\n",
            "Epoch 391/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5969 - val_loss: 5.0597\n",
            "Epoch 392/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5737 - val_loss: 4.8711\n",
            "Epoch 393/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 4.6795\n",
            "Epoch 394/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5265 - val_loss: 4.4555\n",
            "Epoch 395/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5042 - val_loss: 4.2979\n",
            "Epoch 396/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 4.1149\n",
            "Epoch 397/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 3.9542\n",
            "Epoch 398/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 3.7975\n",
            "Epoch 399/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4226 - val_loss: 3.6336\n",
            "Epoch 400/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4032 - val_loss: 3.4778\n",
            "Epoch 401/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 3.3052\n",
            "Epoch 402/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3673 - val_loss: 3.1675\n",
            "Epoch 403/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3509 - val_loss: 3.0342\n",
            "Epoch 404/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3343 - val_loss: 2.8926\n",
            "Epoch 405/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3190 - val_loss: 2.7598\n",
            "Epoch 406/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 2.6476\n",
            "Epoch 407/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2892 - val_loss: 2.5228\n",
            "Epoch 408/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2743 - val_loss: 2.4101\n",
            "Epoch 409/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2616 - val_loss: 2.2929\n",
            "Epoch 410/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2480 - val_loss: 2.1677\n",
            "Epoch 411/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2356 - val_loss: 2.0450\n",
            "Epoch 412/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2244 - val_loss: 1.9448\n",
            "Epoch 413/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2120 - val_loss: 1.8561\n",
            "Epoch 414/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2015 - val_loss: 1.7448\n",
            "Epoch 415/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 1.6713\n",
            "Epoch 416/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1807 - val_loss: 1.5752\n",
            "Epoch 417/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1707 - val_loss: 1.4918\n",
            "Epoch 418/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1619 - val_loss: 1.4141\n",
            "Epoch 419/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 1.3293\n",
            "Epoch 420/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1450 - val_loss: 1.2654\n",
            "Epoch 421/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1378 - val_loss: 1.1943\n",
            "Epoch 422/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 1.1277\n",
            "Epoch 423/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 1.0565\n",
            "Epoch 424/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.9909\n",
            "Epoch 425/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.9400\n",
            "Epoch 426/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1036 - val_loss: 0.8843\n",
            "Epoch 427/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0974 - val_loss: 0.8279\n",
            "Epoch 428/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.7740\n",
            "Epoch 429/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.7355\n",
            "Epoch 430/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.6943\n",
            "Epoch 431/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.6504\n",
            "Epoch 432/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.6104\n",
            "Epoch 433/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.5714\n",
            "Epoch 434/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.5319\n",
            "Epoch 435/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.4939\n",
            "Epoch 436/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.4584\n",
            "Epoch 437/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.4256\n",
            "Epoch 438/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.4008\n",
            "Epoch 439/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.3723\n",
            "Epoch 440/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.3477\n",
            "Epoch 441/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.3249\n",
            "Epoch 442/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.3019\n",
            "Epoch 443/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.2790\n",
            "Epoch 444/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.2584\n",
            "Epoch 445/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.2404\n",
            "Epoch 446/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.2262\n",
            "Epoch 447/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.2098\n",
            "Epoch 448/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.1928\n",
            "Epoch 449/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.1797\n",
            "Epoch 450/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.1659\n",
            "Epoch 451/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.1553\n",
            "Epoch 452/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.1431\n",
            "Epoch 453/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.1337\n",
            "Epoch 454/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.1218\n",
            "Epoch 455/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.1125\n",
            "Epoch 456/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.1052\n",
            "Epoch 457/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0982\n",
            "Epoch 458/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0917\n",
            "Epoch 459/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0850\n",
            "Epoch 460/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0773\n",
            "Epoch 461/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0723\n",
            "Epoch 462/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0673\n",
            "Epoch 463/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0626\n",
            "Epoch 464/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0575\n",
            "Epoch 465/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0561\n",
            "Epoch 466/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0515\n",
            "Epoch 467/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0481\n",
            "Epoch 468/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0450\n",
            "Epoch 469/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0421\n",
            "Epoch 470/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0395\n",
            "Epoch 471/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0372\n",
            "Epoch 472/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0357\n",
            "Epoch 473/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0345\n",
            "Epoch 474/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0327\n",
            "Epoch 475/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0307\n",
            "Epoch 476/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0295\n",
            "Epoch 477/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0286\n",
            "Epoch 478/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0276\n",
            "Epoch 479/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0273\n",
            "Epoch 480/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0258\n",
            "Epoch 481/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0251\n",
            "Epoch 482/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0245\n",
            "Epoch 483/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0243\n",
            "Epoch 484/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0236\n",
            "Epoch 485/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0233\n",
            "Epoch 486/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0234\n",
            "Epoch 487/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0226\n",
            "Epoch 488/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0227\n",
            "Epoch 489/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0223\n",
            "Epoch 490/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0225\n",
            "Epoch 491/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0222\n",
            "Epoch 492/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0225\n",
            "Epoch 493/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0221\n",
            "Epoch 494/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0219\n",
            "Epoch 495/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0227\n",
            "Epoch 496/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0219\n",
            "Epoch 497/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0213\n",
            "Epoch 498/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0222\n",
            "Epoch 499/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0215\n",
            "Epoch 500/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy45B1XVtcRC",
        "outputId": "11f751e8-542a-4594-f341-2be09e45d672"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[88.27033 ]\n",
            " [78.5196  ]\n",
            " [83.946304]\n",
            " ...\n",
            " [85.21169 ]\n",
            " [72.221985]\n",
            " [87.933044]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and test loss histories\n",
        "training_loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, val_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "nuY7LQ0ItkST",
        "outputId": "bfd451de-b2b8-46a0-8857-4899de423ca8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 388,
              "height": 261
            },
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}